{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23249,"databundleVersionId":2399555,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:58:47.049510Z","iopub.execute_input":"2024-05-14T07:58:47.049952Z","iopub.status.idle":"2024-05-14T07:59:04.019822Z","shell.execute_reply.started":"2024-05-14T07:58:47.049918Z","shell.execute_reply":"2024-05-14T07:59:04.018325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\nimport random\n\nplt.style.use('ggplot')\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:59:04.022147Z","iopub.execute_input":"2024-05-14T07:59:04.023905Z","iopub.status.idle":"2024-05-14T07:59:04.604796Z","shell.execute_reply.started":"2024-05-14T07:59:04.023864Z","shell.execute_reply":"2024-05-14T07:59:04.603642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = pd.read_csv(\"../input/g2net-gravitational-wave-detection/training_labels.csv\")\n\n\ndisplay(labels.head())","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:59:04.606379Z","iopub.execute_input":"2024-05-14T07:59:04.606801Z","iopub.status.idle":"2024-05-14T07:59:05.235126Z","shell.execute_reply.started":"2024-05-14T07:59:04.606771Z","shell.execute_reply":"2024-05-14T07:59:05.233919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install optree","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:59:05.237913Z","iopub.execute_input":"2024-05-14T07:59:05.238341Z","iopub.status.idle":"2024-05-14T07:59:22.924658Z","shell.execute_reply.started":"2024-05-14T07:59:05.238307Z","shell.execute_reply":"2024-05-14T07:59:22.922401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install nnAudio","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:59:22.926751Z","iopub.execute_input":"2024-05-14T07:59:22.927143Z","iopub.status.idle":"2024-05-14T07:59:39.075107Z","shell.execute_reply.started":"2024-05-14T07:59:22.927109Z","shell.execute_reply":"2024-05-14T07:59:39.072957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nfrom tensorflow import keras\nfrom keras.utils import Sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPool1D, BatchNormalization\nfrom keras.optimizers import RMSprop,Adam\nimport torch # For deep learning\nfrom nnAudio.Spectrogram import CQT1992v2 # For creating Constant-Q Transform spectrograms\nimport math\nfrom random import shuffle\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:59:39.077525Z","iopub.execute_input":"2024-05-14T07:59:39.078156Z","iopub.status.idle":"2024-05-14T07:59:43.688268Z","shell.execute_reply.started":"2024-05-14T07:59:39.078101Z","shell.execute_reply":"2024-05-14T07:59:43.687104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clase que genera los datos, los randomiza y preprocesa (aplica Q-transform, etc.)\nclass DataGenerator(Sequence):\n    def __init__(self, path, list_IDs, data, batch_size):\n        self.path = path\n        self.list_IDs = list_IDs\n        self.data = data\n        self.batch_size = batch_size\n        self.indexes = np.arange(len(self.list_IDs))\n        \n    def __len__(self):\n        len_ = int(len(self.list_IDs)/self.batch_size)\n        if len_*self.batch_size < len(self.list_IDs):\n            len_ += 1\n        return len_\n    \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n        X, y = self.__data_generation(list_IDs_temp)\n        return X, y\n    \n    def __data_generation(self, list_IDs_temp):\n        X = np.zeros((self.batch_size, 69, 193))\n        y = np.zeros((self.batch_size, 1))\n        for i, ID in enumerate(list_IDs_temp):\n            id_ = self.data.loc[ID, 'id']\n            file = id_+'.npy'\n            path_in = '/'.join([self.path, id_[0], id_[1], id_[2]])+'/'\n            data_array = np.load(path_in+file)\n            #np.hstack() apiles arrays in a horizontal way\n            waves = np.hstack(data_array)\n            #normalize\n            waves = waves / np.max(waves)\n            #we do a pytorch tensor and convert it into float\n            waves = torch.from_numpy(waves).float()\n            transform=CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=64, verbose = False)\n            #Q-transform\n            image = transform(waves)\n            #We turn it back into a numpy array\n            image = np.array(image)\n            #transpose axes into (1,2,0)\n            image = np.transpose(image,(1,2,0))\n            # this creates an array(69, 193, 1) (an image in which the model can identify a signal)\n            # and then we create a pack of images corresponding to the batch size\n            # so the input_shape of the CNN must be (69, 193).\n            X[i, ] = image[:,:,0]\n            y[i, ] = self.data.loc[ID, 'target']\n        X = np.stack(X)\n        y = np.stack(y)\n        return X, y","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:59:43.690413Z","iopub.execute_input":"2024-05-14T07:59:43.691354Z","iopub.status.idle":"2024-05-14T07:59:43.708700Z","shell.execute_reply.started":"2024-05-14T07:59:43.691307Z","shell.execute_reply":"2024-05-14T07:59:43.707412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bayesian Optimization starts here","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport random\nfrom itertools import cycle\n\n\n#the train dataset is split in 16 files (0,1,2,...,e,f) and we will use all of this files separately\ndirectorio = cycle(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f'])","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:59:43.710147Z","iopub.execute_input":"2024-05-14T07:59:43.710536Z","iopub.status.idle":"2024-05-14T07:59:43.729585Z","shell.execute_reply.started":"2024-05-14T07:59:43.710504Z","shell.execute_reply":"2024-05-14T07:59:43.728254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this is the Bayesian Optimization library\n!pip install scikit-optimize","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:59:43.730990Z","iopub.execute_input":"2024-05-14T07:59:43.731514Z","iopub.status.idle":"2024-05-14T07:59:59.487652Z","shell.execute_reply.started":"2024-05-14T07:59:43.731453Z","shell.execute_reply":"2024-05-14T07:59:59.485798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import skopt\nfrom skopt import gp_minimize\nfrom skopt.space import Real, Integer, Categorical\n\n# Definimos las dimensiones de búsqueda. Van a ser un parámetro de entrada imprescindible para gp_minimize\n# Defining the dimensions we are studying, it is essential for gp_minimize\n\n#we will study the logarithm of the number of neurons (base 2) and the number of dense layers\ndim_log_width = Integer(low=4, high=8, name='log_width')\ndim_layers = Integer(low=1, high=5, name='layers')\ndimensions = [dim_log_width, dim_layers]\n\n# The reason why I use numbers in between 2^4 and 2^8 in log_width is\n# that the model becomes unstable for higher widths, Tomas and I suspect it is \n# because each call only uses a small fragment of the dataset. Maybe if we used\n# all the dataset for every call, we would obtain better results, but I don't \n# have enough computational resources for that (it is too expensive).","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:59:59.493133Z","iopub.execute_input":"2024-05-14T07:59:59.494174Z","iopub.status.idle":"2024-05-14T07:59:59.914089Z","shell.execute_reply.started":"2024-05-14T07:59:59.494127Z","shell.execute_reply":"2024-05-14T07:59:59.912647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#These vectors just keep track of the width, layers studied in every step with its accuracy. \n#I have used these values for a plot that shows how gp_minimize explores the hyperparameter space.\nlog_width_history = []\nlayers_history = []\nacc_history = []\n\n\ndef train(params):\n    #every call will use the next file\n    directori = next(directorio)\n    #This selects the file of the dataset\n    train_idx = labels[labels['id'].str.startswith(directori)]['id'].values\n    y = labels[labels['id'].isin(train_idx)]['target'].values\n    #params is a vector with the dimensions (log_width, layers)\n    print(params)\n    log_width, layers = params\n    log_width_history.append(log_width)\n    layers_history.append(layers)\n\n    #Generating the training and validation data\n    train_idx, train_Valx = train_test_split(list(labels[labels['id'].str.startswith(directori)].index), test_size=0.2, random_state=2021)\n    train_generator = DataGenerator('/kaggle/input/g2net-gravitational-wave-detection/train/', train_idx, labels[labels['id'].str.startswith(directori)], 256)\n    val_generator = DataGenerator('/kaggle/input/g2net-gravitational-wave-detection/train/', train_Valx, labels[labels['id'].str.startswith(directori)], 256)\n    \n    # Building the model\n    model = Sequential()\n    model.add(Conv1D(2**log_width, input_shape=(69, 193,), kernel_size=3, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Flatten())\n    for i in range(layers):\n        model.add(Dense(2**log_width, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(optimizer=Adam(learning_rate=2e-4), loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Training the model\n    history = model.fit(train_generator, validation_data=val_generator, epochs=1)\n\n    # We evaluate the model's performance \n    val_loss, val_accuracy = model.evaluate(val_generator)\n    acc_history.append(val_accuracy)\n    # It returns the metrics that we want to optimize with gp_minimize\n    return -val_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:59:59.915664Z","iopub.execute_input":"2024-05-14T07:59:59.916046Z","iopub.status.idle":"2024-05-14T07:59:59.931996Z","shell.execute_reply.started":"2024-05-14T07:59:59.916015Z","shell.execute_reply":"2024-05-14T07:59:59.930649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Choosing our prior (the first set of hyperparameters studied)\ndefault_parameters = [5, 1]","metadata":{"execution":{"iopub.status.busy":"2024-05-14T08:02:45.995455Z","iopub.execute_input":"2024-05-14T08:02:45.995920Z","iopub.status.idle":"2024-05-14T08:02:46.003840Z","shell.execute_reply.started":"2024-05-14T08:02:45.995886Z","shell.execute_reply":"2024-05-14T08:02:46.002218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EI (expected improcvement) ACQ function is the safest in this context. However, PI (probability of improvement) \n# can also be studied. It is a bit more agressive, but might work correctly as well.\n# There are more options for ACQ functions but I am not sure if they will work\n# Here we choose the number of times we want gp_minimize to call the training function.\n# Every call it will study a set of hyperparameters, and it will not use an already used\n# set of training data. \nsearch_result = gp_minimize(\n    func=train,\n    dimensions=dimensions,\n    acq_func='EI',\n    n_calls=16,\n    x0=default_parameters)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T08:02:46.288889Z","iopub.execute_input":"2024-05-14T08:02:46.289331Z","iopub.status.idle":"2024-05-14T11:04:09.185696Z","shell.execute_reply.started":"2024-05-14T08:02:46.289271Z","shell.execute_reply":"2024-05-14T11:04:09.179851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_width = 2**(search_result.x[0])  # the best value of width obtained\nbest_layers = search_result.x[1]  # the best value of layers obtained\nprint(search_result.x)\nfor i in range(len(acc_history)):\n    print(log_width_history[i], layers_history[i], acc_history[i])","metadata":{"execution":{"iopub.status.busy":"2024-05-14T11:04:09.187175Z","iopub.status.idle":"2024-05-14T11:04:09.187717Z","shell.execute_reply.started":"2024-05-14T11:04:09.187462Z","shell.execute_reply":"2024-05-14T11:04:09.187483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Active Learning ends here, and a normal training will be done with the best hyperparameters found\n","metadata":{}},{"cell_type":"code","source":"sample_submission = pd.read_csv('../input/g2net-gravitational-wave-detection/sample_submission.csv')\ntrain_idx =  labels['id'].values\ny = labels['target'].values\ntest_idx = sample_submission['id'].values","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:40:02.738817Z","iopub.execute_input":"2024-04-27T07:40:02.739314Z","iopub.status.idle":"2024-04-27T07:40:03.002225Z","shell.execute_reply.started":"2024-04-27T07:40:02.739264Z","shell.execute_reply":"2024-04-27T07:40:03.000901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_idx, train_Valx = train_test_split(list(labels.index), test_size=0.05, random_state=2021)\ntest_idx = list(sample_submission.index)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:40:03.004103Z","iopub.execute_input":"2024-04-27T07:40:03.004641Z","iopub.status.idle":"2024-04-27T07:40:03.330655Z","shell.execute_reply.started":"2024-04-27T07:40:03.004608Z","shell.execute_reply":"2024-04-27T07:40:03.329615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = DataGenerator('/kaggle/input/g2net-gravitational-wave-detection/train/', train_idx, labels, 256)\nval_generator = DataGenerator('/kaggle/input/g2net-gravitational-wave-detection/train/', train_Valx, labels, 256)\ntest_generator = DataGenerator('/kaggle/input/g2net-gravitational-wave-detection/test/', test_idx, sample_submission, 256)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:40:03.332243Z","iopub.execute_input":"2024-04-27T07:40:03.333222Z","iopub.status.idle":"2024-04-27T07:40:03.338624Z","shell.execute_reply.started":"2024-04-27T07:40:03.333191Z","shell.execute_reply":"2024-04-27T07:40:03.337735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv1D(best_width, input_shape=(69, 193,), kernel_size=3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nfor i in range(best_layers):\n    model.add(Dense(best_width, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer=Adam(learning_rate=2e-4), loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:40:03.340087Z","iopub.execute_input":"2024-04-27T07:40:03.341033Z","iopub.status.idle":"2024-04-27T07:40:03.900265Z","shell.execute_reply.started":"2024-04-27T07:40:03.340998Z","shell.execute_reply":"2024-04-27T07:40:03.898801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:40:03.902378Z","iopub.execute_input":"2024-04-27T07:40:03.902722Z","iopub.status.idle":"2024-04-27T07:40:03.929556Z","shell.execute_reply.started":"2024-04-27T07:40:03.902695Z","shell.execute_reply":"2024-04-27T07:40:03.928347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator, validation_data=val_generator, epochs = 1)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:40:22.321923Z","iopub.execute_input":"2024-04-27T07:40:22.322808Z","iopub.status.idle":"2024-04-27T12:04:00.141473Z","shell.execute_reply.started":"2024-04-27T07:40:22.322769Z","shell.execute_reply":"2024-04-27T12:04:00.136162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = model.predict(test_generator, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T12:04:00.148929Z","iopub.execute_input":"2024-04-27T12:04:00.149473Z","iopub.status.idle":"2024-04-27T13:51:58.493572Z","shell.execute_reply.started":"2024-04-27T12:04:00.149435Z","shell.execute_reply":"2024-04-27T13:51:58.489277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission['target'] = predict[:len(sample_submission)]","metadata":{"execution":{"iopub.status.busy":"2024-04-27T13:51:58.498948Z","iopub.execute_input":"2024-04-27T13:51:58.499600Z","iopub.status.idle":"2024-04-27T13:51:58.521480Z","shell.execute_reply.started":"2024-04-27T13:51:58.499558Z","shell.execute_reply":"2024-04-27T13:51:58.520359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T13:51:58.525123Z","iopub.execute_input":"2024-04-27T13:51:58.525900Z","iopub.status.idle":"2024-04-27T13:51:59.190110Z","shell.execute_reply.started":"2024-04-27T13:51:58.525859Z","shell.execute_reply":"2024-04-27T13:51:59.188740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_submission = pd.read_csv(\"./submission.csv\")\nmy_submission","metadata":{"execution":{"iopub.status.busy":"2024-04-27T13:51:59.192018Z","iopub.execute_input":"2024-04-27T13:51:59.192519Z","iopub.status.idle":"2024-04-27T13:51:59.463312Z","shell.execute_reply.started":"2024-04-27T13:51:59.192473Z","shell.execute_reply":"2024-04-27T13:51:59.461837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nprint(os.listdir(\".\"))\nprint(os.listdir(\"/kaggle/working\"))","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:57:43.559951Z","iopub.status.idle":"2024-04-26T17:57:43.560534Z","shell.execute_reply.started":"2024-04-26T17:57:43.560232Z","shell.execute_reply":"2024-04-26T17:57:43.560254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-24T19:17:50.014603Z","iopub.execute_input":"2024-04-24T19:17:50.015308Z","iopub.status.idle":"2024-04-24T19:17:52.103180Z","shell.execute_reply.started":"2024-04-24T19:17:50.015246Z","shell.execute_reply":"2024-04-24T19:17:52.101472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}